{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle as pkl\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "data_dir = \"data/framing_politicians/morals/\"\n",
    "target = \"all\"  # or single instance like BLM\n",
    "word2vec_file = \"glove.840B.300d_w2v.txt\"\n",
    "word2vec_restricted_file = \"glove.840B.300d_w2v_restricted.txt\"\n",
    "quick_run = False  # use it to limit word2vec loading, to quickly run results, final runs showed be set to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we run the frame axis against Twitter Data\n",
    "\n",
    "The data is assumed to be already aggregated.  \n",
    "\n",
    "The following resources are needed:\n",
    "- Tweets for evaluation\n",
    "- Annotations of Tweets\n",
    "- Word2Vec Model\n",
    "- FrameAxis with Moral Dictionary\n",
    "\n",
    "The results shall reflect the results of the moral framing paper, but might be a bit different due to the rehydration process for twitter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21364 entries, 505332707002683392 to 265494444399263744\n",
      "Data columns (total 34 columns):\n",
      " #   Column                     Non-Null Count  Dtype              \n",
      "---  ------                     --------------  -----              \n",
      " 0   created_at                 21364 non-null  datetime64[ns, UTC]\n",
      " 1   id_str                     21364 non-null  int64              \n",
      " 2   full_text                  21364 non-null  object             \n",
      " 3   truncated                  21364 non-null  bool               \n",
      " 4   display_text_range         21364 non-null  object             \n",
      " 5   entities                   21364 non-null  object             \n",
      " 6   source                     21364 non-null  object             \n",
      " 7   in_reply_to_status_id      2343 non-null   float64            \n",
      " 8   in_reply_to_status_id_str  2343 non-null   float64            \n",
      " 9   in_reply_to_user_id        2983 non-null   float64            \n",
      " 10  in_reply_to_user_id_str    2983 non-null   float64            \n",
      " 11  in_reply_to_screen_name    2983 non-null   object             \n",
      " 12  user                       21364 non-null  object             \n",
      " 13  geo                        326 non-null    object             \n",
      " 14  coordinates                326 non-null    object             \n",
      " 15  place                      866 non-null    object             \n",
      " 16  contributors               0 non-null      float64            \n",
      " 17  is_quote_status            21364 non-null  bool               \n",
      " 18  retweet_count              21364 non-null  int64              \n",
      " 19  favorite_count             21364 non-null  int64              \n",
      " 20  favorited                  21364 non-null  bool               \n",
      " 21  retweeted                  21364 non-null  bool               \n",
      " 22  lang                       21364 non-null  object             \n",
      " 23  extended_entities          2437 non-null   object             \n",
      " 24  possibly_sensitive         7464 non-null   float64            \n",
      " 25  quoted_status_id           820 non-null    float64            \n",
      " 26  quoted_status_id_str       820 non-null    float64            \n",
      " 27  quoted_status_permalink    820 non-null    object             \n",
      " 28  quoted_status              590 non-null    object             \n",
      " 29  retweeted_status           2860 non-null   object             \n",
      " 30  withheld_in_countries      14 non-null     object             \n",
      " 31  scopes                     6 non-null      object             \n",
      " 32  withheld_scope             2 non-null      object             \n",
      " 33  withheld_copyright         2 non-null      float64            \n",
      "dtypes: bool(4), datetime64[ns, UTC](1), float64(9), int64(3), object(17)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets_df = pd.read_json(data_dir + target + \".jsonl\", lines=True).set_index(\"id\")\n",
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 34987 entries, 521033092132503552 to 265600333068238849\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   care         6468 non-null   float64\n",
      " 1   purity       3149 non-null   float64\n",
      " 2   subversion   6908 non-null   float64\n",
      " 3   loyalty      6276 non-null   float64\n",
      " 4   harm         9203 non-null   float64\n",
      " 5   cheating     8168 non-null   float64\n",
      " 6   fairness     6112 non-null   float64\n",
      " 7   non-moral    24404 non-null  float64\n",
      " 8   betrayal     5362 non-null   float64\n",
      " 9   authority    6485 non-null   float64\n",
      " 10  degradation  5002 non-null   float64\n",
      " 11  nh           1 non-null      float64\n",
      " 12  nm           109 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "moral_df = pd.read_csv(data_dir + target + \"_morals.csv\").set_index(\"id\")\n",
    "moral_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21602 entries, 20 to 844281435922075648\n",
      "Data columns (total 47 columns):\n",
      " #   Column                     Non-Null Count  Dtype              \n",
      "---  ------                     --------------  -----              \n",
      " 0   created_at                 21602 non-null  datetime64[ns, UTC]\n",
      " 1   id_str                     21602 non-null  int64              \n",
      " 2   full_text                  21602 non-null  object             \n",
      " 3   truncated                  21602 non-null  bool               \n",
      " 4   display_text_range         21602 non-null  object             \n",
      " 5   entities                   21602 non-null  object             \n",
      " 6   source                     21602 non-null  object             \n",
      " 7   in_reply_to_status_id      2353 non-null   float64            \n",
      " 8   in_reply_to_status_id_str  2353 non-null   float64            \n",
      " 9   in_reply_to_user_id        3003 non-null   float64            \n",
      " 10  in_reply_to_user_id_str    3003 non-null   float64            \n",
      " 11  in_reply_to_screen_name    3003 non-null   object             \n",
      " 12  user                       21602 non-null  object             \n",
      " 13  geo                        328 non-null    object             \n",
      " 14  coordinates                328 non-null    object             \n",
      " 15  place                      878 non-null    object             \n",
      " 16  contributors               0 non-null      float64            \n",
      " 17  is_quote_status            21602 non-null  bool               \n",
      " 18  retweet_count              21602 non-null  int64              \n",
      " 19  favorite_count             21602 non-null  int64              \n",
      " 20  favorited                  21602 non-null  bool               \n",
      " 21  retweeted                  21602 non-null  bool               \n",
      " 22  lang                       21602 non-null  object             \n",
      " 23  extended_entities          2467 non-null   object             \n",
      " 24  possibly_sensitive         7574 non-null   float64            \n",
      " 25  quoted_status_id           836 non-null    float64            \n",
      " 26  quoted_status_id_str       836 non-null    float64            \n",
      " 27  quoted_status_permalink    836 non-null    object             \n",
      " 28  quoted_status              602 non-null    object             \n",
      " 29  retweeted_status           2860 non-null   object             \n",
      " 30  withheld_in_countries      14 non-null     object             \n",
      " 31  scopes                     6 non-null      object             \n",
      " 32  withheld_scope             2 non-null      object             \n",
      " 33  withheld_copyright         2 non-null      float64            \n",
      " 34  care                       4467 non-null   float64            \n",
      " 35  purity                     2110 non-null   float64            \n",
      " 36  subversion                 3270 non-null   float64            \n",
      " 37  loyalty                    4099 non-null   float64            \n",
      " 38  harm                       5654 non-null   float64            \n",
      " 39  cheating                   4561 non-null   float64            \n",
      " 40  fairness                   3898 non-null   float64            \n",
      " 41  non-moral                  15489 non-null  float64            \n",
      " 42  betrayal                   2703 non-null   float64            \n",
      " 43  authority                  3588 non-null   float64            \n",
      " 44  degradation                1921 non-null   float64            \n",
      " 45  nh                         0 non-null      float64            \n",
      " 46  nm                         86 non-null     float64            \n",
      "dtypes: bool(4), datetime64[ns, UTC](1), float64(22), int64(3), object(17)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets_df = tweets_df.merge(moral_df, left_index=True, right_index=True)\n",
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that there can be overlap\n",
    "# We will filter those out\n",
    "assert len(tweets_df[(tweets_df[\"care\"] >= 2) & (tweets_df[\"harm\"] >= 2)][[\"care\", \"harm\"]]) > 0\n",
    "assert len(tweets_df[(tweets_df[\"purity\"] >= 2) & (tweets_df[\"degradation\"] >= 2)][[\"purity\", \"degradation\"]]) > 0\n",
    "assert len(tweets_df[(tweets_df[\"authority\"] >= 2) & (tweets_df[\"subversion\"] >= 2)][[\"authority\", \"subversion\"]]) > 0\n",
    "assert len(tweets_df[(tweets_df[\"loyalty\"] >= 2) & (tweets_df[\"betrayal\"] >= 2)][[\"loyalty\", \"betrayal\"]]) > 0\n",
    "assert len(tweets_df[(tweets_df[\"fairness\"] >= 2) & (tweets_df[\"cheating\"] >= 2)][[\"fairness\", \"cheating\"]]) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and FrameAxis approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if quick_run:\n",
    "    model = KeyedVectors.load_word2vec_format(word2vec_file, limit=5000)\n",
    "else:\n",
    "    model = KeyedVectors.load_word2vec_format(word2vec_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run frame_axis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FrameSystem.load(\"moral.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'care/harm': <__main__.FrameAxis at 0x7fe40da8bd90>,\n",
       " 'fairness/cheating': <__main__.FrameAxis at 0x7fe40da8bf70>,\n",
       " 'loyalty/betrayal': <__main__.FrameAxis at 0x7fe40da8bfa0>,\n",
       " 'authority/subversion': <__main__.FrameAxis at 0x7fe40da8beb0>,\n",
       " 'sanctity/degradation': <__main__.FrameAxis at 0x7fe40da8b850>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.frame_axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fs = FrameSystem(frame_axes)\n",
    "tweets_df = fs.transform_df(tweets_df, \"full_text\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on specific features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def axis_classification_report_individual(pos, neg, axis_bias, axis_inte):\n",
    "    return axis_classification_report(pos, neg, axis_cols=[axis_bias, axis_inte])  # important only take the two dimension in question here\n",
    "\n",
    "def axis_classification_report(pos, neg, axis_cols):\n",
    "    \"\"\"\n",
    "    Peforms the classification and returns the report.\n",
    "    The parameter axis_cols defines the columns to train on.\n",
    "    \"\"\"\n",
    "    tweets_df_axis = tweets_df[(tweets_df[pos] > 2) | (tweets_df[neg] > 2)]\n",
    "    X_axis = tweets_df_axis[axis_cols].values\n",
    "    Y_axis =  tweets_df_axis[pos].values\n",
    "    Y_axis = np.where(Y_axis >= 2, 1, 0)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_axis, Y_axis, test_size=0.25, shuffle=True)\n",
    "    classifier = LogisticRegression(class_weight=\"balanced\").fit(X_train, Y_train)  # penalty=\"l1\", solver=\"saga\"\n",
    "    \n",
    "    Y_pred = classifier.predict(X_test)\n",
    "    print(f\"{pos} - {neg}\")\n",
    "    print(classification_report(Y_test, Y_pred))\n",
    "    return classification_report(Y_test, Y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authority - subversion\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81        80\n",
      "           1       0.74      0.74      0.74        58\n",
      "\n",
      "    accuracy                           0.78       138\n",
      "   macro avg       0.78      0.78      0.78       138\n",
      "weighted avg       0.78      0.78      0.78       138\n",
      "\n",
      "fairness - cheating\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68       254\n",
      "           1       0.64      0.67      0.65       228\n",
      "\n",
      "    accuracy                           0.67       482\n",
      "   macro avg       0.67      0.67      0.67       482\n",
      "weighted avg       0.67      0.67      0.67       482\n",
      "\n",
      "care - harm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85       288\n",
      "           1       0.76      0.90      0.82       208\n",
      "\n",
      "    accuracy                           0.84       496\n",
      "   macro avg       0.84      0.85      0.84       496\n",
      "weighted avg       0.85      0.84      0.84       496\n",
      "\n",
      "loyalty - betrayal\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.71      0.49        49\n",
      "           1       0.88      0.64      0.74       167\n",
      "\n",
      "    accuracy                           0.66       216\n",
      "   macro avg       0.63      0.68      0.61       216\n",
      "weighted avg       0.77      0.66      0.68       216\n",
      "\n",
      "purity - degradation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91        49\n",
      "           1       0.95      0.84      0.89        43\n",
      "\n",
      "    accuracy                           0.90        92\n",
      "   macro avg       0.91      0.90      0.90        92\n",
      "weighted avg       0.91      0.90      0.90        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auth_res = axis_classification_report_individual(\"authority\", \"subversion\", \"auth_bias\", \"auth_inte\")\n",
    "fair_res = axis_classification_report_individual(\"fairness\", \"cheating\", \"fair_bias\", \"fair_inte\")\n",
    "care_res = axis_classification_report_individual(\"care\", \"harm\", \"care_bias\", \"care_inte\")\n",
    "loya_res = axis_classification_report_individual(\"loyalty\", \"betrayal\", \"loya_bias\", \"loya_inte\")\n",
    "pure_res = axis_classification_report_individual(\"purity\", \"degradation\", \"sanc_bias\", \"sanc_inte\")\n",
    "pass  # supress dict ouput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order as table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_classification_reports(dict_list, name_list):\n",
    "    res_df = pd.DataFrame(dict_list)\n",
    "    all_res_df = pd.concat([\n",
    "        res_df, \n",
    "        pd.json_normalize(res_df['0']).add_prefix(\"0_\"),\n",
    "         pd.json_normalize(res_df['1']).add_prefix(\"1_\"),\n",
    "         pd.json_normalize(res_df['macro avg']).add_prefix(\"macro_avg_\"),\n",
    "         pd.json_normalize(res_df['weighted avg']).add_prefix(\"weighted_avg_\"),\n",
    "    ], axis=1).drop([\"0\", \"1\", \"macro avg\", \"weighted avg\"], axis=1)\n",
    "    all_res_df.index = name_list\n",
    "    return all_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_avg_precision</th>\n",
       "      <th>weighted_avg_recall</th>\n",
       "      <th>weighted_avg_f1-score</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auth</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fair</th>\n",
       "      <td>0.666880</td>\n",
       "      <td>0.665975</td>\n",
       "      <td>0.666195</td>\n",
       "      <td>0.665975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>care</th>\n",
       "      <td>0.850251</td>\n",
       "      <td>0.836694</td>\n",
       "      <td>0.837762</td>\n",
       "      <td>0.836694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loya</th>\n",
       "      <td>0.767270</td>\n",
       "      <td>0.657407</td>\n",
       "      <td>0.684767</td>\n",
       "      <td>0.657407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pure</th>\n",
       "      <td>0.906359</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.901529</td>\n",
       "      <td>0.902174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>0.794674</td>\n",
       "      <td>0.768972</td>\n",
       "      <td>0.774572</td>\n",
       "      <td>0.768972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      weighted_avg_precision  weighted_avg_recall  weighted_avg_f1-score  \\\n",
       "auth                0.782609             0.782609               0.782609   \n",
       "fair                0.666880             0.665975               0.666195   \n",
       "care                0.850251             0.836694               0.837762   \n",
       "loya                0.767270             0.657407               0.684767   \n",
       "pure                0.906359             0.902174               0.901529   \n",
       "avg                 0.794674             0.768972               0.774572   \n",
       "\n",
       "      accuracy  \n",
       "auth  0.782609  \n",
       "fair  0.665975  \n",
       "care  0.836694  \n",
       "loya  0.657407  \n",
       "pure  0.902174  \n",
       "avg   0.768972  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute averages\n",
    "dict_list = [auth_res, fair_res, care_res, loya_res, pure_res]\n",
    "name_list = [\"auth\", \"fair\", \"care\", \"loya\", \"pure\"]\n",
    "all_res_df = combine_classification_reports(dict_list, name_list)\n",
    "all_res_df.loc[\"avg\"] = all_res_df.mean()\n",
    "all_res_df[[\"weighted_avg_precision\", \"weighted_avg_recall\", \"weighted_avg_f1-score\", \"accuracy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &  weighted\\_avg\\_precision &  weighted\\_avg\\_recall &  weighted\\_avg\\_f1-score &  accuracy \\\\\n",
      "\\midrule\n",
      "auth &                   0.783 &                0.783 &                  0.783 &     0.783 \\\\\n",
      "fair &                   0.667 &                0.666 &                  0.666 &     0.666 \\\\\n",
      "care &                   0.850 &                0.837 &                  0.838 &     0.837 \\\\\n",
      "loya &                   0.767 &                0.657 &                  0.685 &     0.657 \\\\\n",
      "pure &                   0.906 &                0.902 &                  0.902 &     0.902 \\\\\n",
      "avg  &                   0.795 &                0.769 &                  0.775 &     0.769 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(all_res_df[[\"weighted_avg_precision\", \"weighted_avg_recall\", \"weighted_avg_f1-score\", \"accuracy\"]].to_latex(float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on all available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authority - subversion\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75        70\n",
      "           1       0.74      0.76      0.75        68\n",
      "\n",
      "    accuracy                           0.75       138\n",
      "   macro avg       0.75      0.75      0.75       138\n",
      "weighted avg       0.75      0.75      0.75       138\n",
      "\n",
      "fairness - cheating\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75       260\n",
      "           1       0.70      0.71      0.71       222\n",
      "\n",
      "    accuracy                           0.73       482\n",
      "   macro avg       0.73      0.73      0.73       482\n",
      "weighted avg       0.73      0.73      0.73       482\n",
      "\n",
      "care - harm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85       283\n",
      "           1       0.78      0.82      0.80       213\n",
      "\n",
      "    accuracy                           0.83       496\n",
      "   macro avg       0.82      0.83      0.82       496\n",
      "weighted avg       0.83      0.83      0.83       496\n",
      "\n",
      "loyalty - betrayal\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76        48\n",
      "           1       0.94      0.91      0.93       168\n",
      "\n",
      "    accuracy                           0.89       216\n",
      "   macro avg       0.83      0.86      0.85       216\n",
      "weighted avg       0.90      0.89      0.89       216\n",
      "\n",
      "purity - degradation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88        45\n",
      "           1       0.89      0.87      0.88        47\n",
      "\n",
      "    accuracy                           0.88        92\n",
      "   macro avg       0.88      0.88      0.88        92\n",
      "weighted avg       0.88      0.88      0.88        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moral_cols = [\"auth_bias\", \"auth_inte\", \"fair_bias\", \"fair_inte\", \"care_bias\", \"care_inte\", \"loya_bias\", \"loya_inte\", \"sanc_bias\", \"sanc_inte\"]\n",
    "auth_res = axis_classification_report(\"authority\", \"subversion\", moral_cols)\n",
    "fair_res = axis_classification_report(\"fairness\", \"cheating\", moral_cols)\n",
    "care_res = axis_classification_report(\"care\", \"harm\", moral_cols)\n",
    "loya_res = axis_classification_report(\"loyalty\", \"betrayal\", moral_cols)\n",
    "pure_res = axis_classification_report(\"purity\", \"degradation\", moral_cols)\n",
    "pass  # supress dict ouput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_avg_precision</th>\n",
       "      <th>weighted_avg_recall</th>\n",
       "      <th>weighted_avg_f1-score</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auth</th>\n",
       "      <td>0.753940</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fair</th>\n",
       "      <td>0.728519</td>\n",
       "      <td>0.728216</td>\n",
       "      <td>0.728339</td>\n",
       "      <td>0.728216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>care</th>\n",
       "      <td>0.828146</td>\n",
       "      <td>0.826613</td>\n",
       "      <td>0.827042</td>\n",
       "      <td>0.826613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loya</th>\n",
       "      <td>0.895062</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.891147</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pure</th>\n",
       "      <td>0.880671</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.880449</td>\n",
       "      <td>0.880435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>0.817268</td>\n",
       "      <td>0.815555</td>\n",
       "      <td>0.816120</td>\n",
       "      <td>0.815555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      weighted_avg_precision  weighted_avg_recall  weighted_avg_f1-score  \\\n",
       "auth                0.753940             0.753623               0.753623   \n",
       "fair                0.728519             0.728216               0.728339   \n",
       "care                0.828146             0.826613               0.827042   \n",
       "loya                0.895062             0.888889               0.891147   \n",
       "pure                0.880671             0.880435               0.880449   \n",
       "avg                 0.817268             0.815555               0.816120   \n",
       "\n",
       "      accuracy  \n",
       "auth  0.753623  \n",
       "fair  0.728216  \n",
       "care  0.826613  \n",
       "loya  0.888889  \n",
       "pure  0.880435  \n",
       "avg   0.815555  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute averages\n",
    "dict_list = [auth_res, fair_res, care_res, loya_res, pure_res]\n",
    "name_list = [\"auth\", \"fair\", \"care\", \"loya\", \"pure\"]\n",
    "all_res_df = combine_classification_reports(dict_list, name_list)\n",
    "all_res_df.loc[\"avg\"] = all_res_df.mean()\n",
    "all_res_df[[\"weighted_avg_precision\", \"weighted_avg_recall\", \"weighted_avg_f1-score\", \"accuracy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &  weighted\\_avg\\_precision &  weighted\\_avg\\_recall &  weighted\\_avg\\_f1-score &  accuracy \\\\\n",
      "\\midrule\n",
      "auth &                   0.754 &                0.754 &                  0.754 &     0.754 \\\\\n",
      "fair &                   0.729 &                0.728 &                  0.728 &     0.728 \\\\\n",
      "care &                   0.828 &                0.827 &                  0.827 &     0.827 \\\\\n",
      "loya &                   0.895 &                0.889 &                  0.891 &     0.889 \\\\\n",
      "pure &                   0.881 &                0.880 &                  0.880 &     0.880 \\\\\n",
      "avg  &                   0.817 &                0.816 &                  0.816 &     0.816 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(all_res_df[[\"weighted_avg_precision\", \"weighted_avg_recall\", \"weighted_avg_f1-score\", \"accuracy\"]].to_latex(float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polarice",
   "language": "python",
   "name": "polarice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
